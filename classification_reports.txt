model: logistic, scale: None
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.76      0.63      0.69       297

    accuracy                           1.00    170436
   macro avg       0.88      0.82      0.84    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.71      0.67      0.69        90

    accuracy                           1.00     56960
   macro avg       0.85      0.83      0.84     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.65      0.65      0.65        97

    accuracy                           1.00     56960
   macro avg       0.82      0.82      0.82     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.68      0.73        97

    accuracy                           1.00     56960
   macro avg       0.90      0.84      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, model params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.64      0.75       297

    accuracy                           1.00    170436
   macro avg       0.96      0.82      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.63      0.70        97

    accuracy                           1.00     56960
   macro avg       0.90      0.81      0.85     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, model params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.64      0.75       297

    accuracy                           1.00    170436
   macro avg       0.95      0.82      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.64      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.66      0.72        97

    accuracy                           1.00     56960
   macro avg       0.89      0.83      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, model params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.64      0.75       297

    accuracy                           1.00    170436
   macro avg       0.95      0.82      0.87    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.66      0.72        97

    accuracy                           1.00     56960
   macro avg       0.89      0.83      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, model params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.65      0.76       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.66      0.72        97

    accuracy                           1.00     56960
   macro avg       0.89      0.83      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.65      0.76       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.66      0.72        97

    accuracy                           1.00     56960
   macro avg       0.89      0.83      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 0.4, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.66      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.64      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.67      0.72        97

    accuracy                           1.00     56960
   macro avg       0.89      0.83      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 0.9, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.66      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.64      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.68      0.73        97

    accuracy                           1.00     56960
   macro avg       0.90      0.84      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 0.01, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.56      0.69       297

    accuracy                           1.00    170436
   macro avg       0.95      0.78      0.84    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.58      0.70        90

    accuracy                           1.00     56960
   macro avg       0.94      0.79      0.85     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.58      0.67        97

    accuracy                           1.00     56960
   macro avg       0.90      0.79      0.84     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 5, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.64      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.70      0.75        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.64      0.75       297

    accuracy                           1.00    170436
   macro avg       0.96      0.82      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.64      0.70        97

    accuracy                           1.00     56960
   macro avg       0.89      0.82      0.85     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.91      0.64      0.75       297

    accuracy                           1.00    170436
   macro avg       0.95      0.82      0.87    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.66      0.72        97

    accuracy                           1.00     56960
   macro avg       0.89      0.83      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 0.9, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.68      0.73        97

    accuracy                           1.00     56960
   macro avg       0.90      0.84      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 40, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.68      0.73        97

    accuracy                           1.00     56960
   macro avg       0.90      0.84      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote              precision    recall  f1-score   support

           0       0.99      1.00      1.00    170139
           1       0.99      0.93      0.96     17013

    accuracy                           0.99    187152
   macro avg       0.99      0.96      0.98    187152
weighted avg       0.99      0.99      0.99    187152
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.63      0.81      0.71        90

    accuracy                           1.00     56960
   macro avg       0.81      0.91      0.85     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.59      0.86      0.70        97

    accuracy                           1.00     56960
   macro avg       0.80      0.93      0.85     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.84      0.90      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.92      0.95    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.77      0.80        90

    accuracy                           1.00     56960
   macro avg       0.92      0.88      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.72      0.84      0.77        97

    accuracy                           1.00     56960
   macro avg       0.86      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       0.99      1.00      1.00    170139
           1       0.99      0.92      0.96     15312

    accuracy                           0.99    185451
   macro avg       0.99      0.96      0.98    185451
weighted avg       0.99      0.99      0.99    185451
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.63      0.80      0.70        90

    accuracy                           1.00     56960
   macro avg       0.81      0.90      0.85     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.61      0.86      0.71        97

    accuracy                           1.00     56960
   macro avg       0.81      0.93      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.79      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.80      0.77      0.78        90

    accuracy                           1.00     56960
   macro avg       0.90      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.81      0.78        97

    accuracy                           1.00     56960
   macro avg       0.87      0.91      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       0.99      1.00      1.00    170139
           1       0.98      0.83      0.90      6805

    accuracy                           0.99    176944
   macro avg       0.99      0.92      0.95    176944
weighted avg       0.99      0.99      0.99    176944
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.67      0.79      0.72        90

    accuracy                           1.00     56960
   macro avg       0.83      0.89      0.86     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.62      0.86      0.72        97

    accuracy                           1.00     56960
   macro avg       0.81      0.93      0.86     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       0.98      1.00      0.99    170139
           1       0.97      0.85      0.90     17013

    accuracy                           0.98    187152
   macro avg       0.98      0.92      0.95    187152
weighted avg       0.98      0.98      0.98    187152
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.36      0.82      0.50        90

    accuracy                           1.00     56960
   macro avg       0.68      0.91      0.75     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.37      0.87      0.52        97

    accuracy                           1.00     56960
   macro avg       0.69      0.93      0.76     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       0.92      0.97      0.95    170139
           1       0.97      0.92      0.94    170139

    accuracy                           0.95    340278
   macro avg       0.95      0.95      0.95    340278
weighted avg       0.95      0.95      0.95    340278
              precision    recall  f1-score   support

           0       1.00      0.97      0.99     56870
           1       0.05      0.89      0.09        90

    accuracy                           0.97     56960
   macro avg       0.52      0.93      0.54     56960
weighted avg       1.00      0.97      0.98     56960
              precision    recall  f1-score   support

           0       1.00      0.97      0.99     56863
           1       0.05      0.91      0.10        97

    accuracy                           0.97     56960
   macro avg       0.53      0.94      0.54     56960
weighted avg       1.00      0.97      0.98     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       0.94      0.98      0.96    170139
           1       0.97      0.89      0.93    102083

    accuracy                           0.95    272222
   macro avg       0.95      0.94      0.95    272222
weighted avg       0.95      0.95      0.95    272222
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     56870
           1       0.08      0.88      0.14        90

    accuracy                           0.98     56960
   macro avg       0.54      0.93      0.57     56960
weighted avg       1.00      0.98      0.99     56960
              precision    recall  f1-score   support

           0       1.00      0.98      0.99     56863
           1       0.08      0.91      0.15        97

    accuracy                           0.98     56960
   macro avg       0.54      0.95      0.57     56960
weighted avg       1.00      0.98      0.99     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       0.99      1.00      1.00    170139
           1       0.98      0.83      0.90      8506

    accuracy                           0.99    178645
   macro avg       0.99      0.92      0.95    178645
weighted avg       0.99      0.99      0.99    178645
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.58      0.79      0.67        90

    accuracy                           1.00     56960
   macro avg       0.79      0.89      0.83     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.56      0.86      0.67        97

    accuracy                           1.00     56960
   macro avg       0.78      0.93      0.84     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: standard, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.79      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.80      0.77      0.78        90

    accuracy                           1.00     56960
   macro avg       0.90      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.81      0.78        97

    accuracy                           1.00     56960
   macro avg       0.87      0.91      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: minmax, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.76      0.85      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.88      0.92    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.85      0.77      0.81        90

    accuracy                           1.00     56960
   macro avg       0.93      0.88      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.80      0.78        97

    accuracy                           1.00     56960
   macro avg       0.87      0.90      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 0 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.64      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 15, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 80, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l1', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.70      0.75        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 80, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.90      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.95      0.83      0.88    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.63      0.75        90

    accuracy                           1.00     56960
   macro avg       0.95      0.82      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.70      0.75        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic, scale: robust, feature engineering: 1 ,model params: {'C': 80, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 17, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      0.97      0.99    170139
           1       0.05      0.91      0.10       297

    accuracy                           0.97    170436
   macro avg       0.53      0.94      0.54    170436
weighted avg       1.00      0.97      0.98    170436
              precision    recall  f1-score   support

           0       1.00      0.97      0.99     56870
           1       0.05      0.89      0.10        90

    accuracy                           0.97     56960
   macro avg       0.53      0.93      0.54     56960
weighted avg       1.00      0.97      0.99     56960
              precision    recall  f1-score   support

           0       1.00      0.97      0.99     56863
           1       0.06      0.92      0.11        97

    accuracy                           0.97     56960
   macro avg       0.53      0.95      0.55     56960
weighted avg       1.00      0.97      0.99     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 1.0, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : None 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.92      0.67      0.77       297

    accuracy                           1.00    170436
   macro avg       0.96      0.83      0.89    170436
weighted avg       1.00      1.00      1.00    170436
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.66      0.76        90

    accuracy                           1.00     56960
   macro avg       0.95      0.83      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.69      0.74        97

    accuracy                           1.00     56960
   macro avg       0.90      0.85      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : smote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.96      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.98      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.77      0.80        90

    accuracy                           1.00     56960
   macro avg       0.92      0.88      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 10.0, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : bsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.95      0.80      0.87      1701

    accuracy                           1.00    171840
   macro avg       0.97      0.90      0.93    171840
weighted avg       1.00      1.00      1.00    171840
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.78      0.79      0.78        90

    accuracy                           1.00     56960
   macro avg       0.89      0.89      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.70      0.84      0.76        97

    accuracy                           1.00     56960
   macro avg       0.85      0.92      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 10.0, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'} 
oversampling type : bsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170139
           1       0.95      0.88      0.92      5104

    accuracy                           1.00    175243
   macro avg       0.97      0.94      0.96    175243
weighted avg       1.00      1.00      1.00    175243
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.50      0.79      0.61        90

    accuracy                           1.00     56960
   macro avg       0.75      0.89      0.81     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.50      0.87      0.64        97

    accuracy                           1.00     56960
   macro avg       0.75      0.93      0.82     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.96      0.80      0.87      1696

    accuracy                           1.00    171830
   macro avg       0.98      0.90      0.94    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.77      0.80        90

    accuracy                           1.00     56960
   macro avg       0.92      0.88      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 1.0, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       0.98      1.00      0.99    170139
           1       0.97      0.85      0.90     17013

    accuracy                           0.98    187152
   macro avg       0.98      0.92      0.95    187152
weighted avg       0.98      0.98      0.98    187152
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.36      0.82      0.50        90

    accuracy                           1.00     56960
   macro avg       0.68      0.91      0.75     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.38      0.87      0.52        97

    accuracy                           1.00     56960
   macro avg       0.69      0.93      0.76     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 10.0, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       0.99      1.00      1.00    170138
           1       0.98      0.82      0.90      5103

    accuracy                           0.99    175241
   macro avg       0.99      0.91      0.95    175241
weighted avg       0.99      0.99      0.99    175241
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.73      0.78      0.75        90

    accuracy                           1.00     56960
   macro avg       0.86      0.89      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.69      0.86      0.76        97

    accuracy                           1.00     56960
   macro avg       0.84      0.93      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: standard, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.93    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.96      0.80      0.87      1696

    accuracy                           1.00    171830
   macro avg       0.98      0.90      0.94    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.77      0.80        90

    accuracy                           1.00     56960
   macro avg       0.92      0.88      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'} 
oversampling type : under 
              precision    recall  f1-score   support

           0       0.80      0.90      0.85       302
           1       0.88      0.78      0.83       297

    accuracy                           0.84       599
   macro avg       0.84      0.84      0.84       599
weighted avg       0.84      0.84      0.84       599
              precision    recall  f1-score   support

           0       1.00      0.99      0.99     56870
           1       0.09      0.77      0.16        90

    accuracy                           0.99     56960
   macro avg       0.55      0.88      0.58     56960
weighted avg       1.00      0.99      0.99     56960
              precision    recall  f1-score   support

           0       1.00      0.99      0.99     56863
           1       0.11      0.78      0.19        97

    accuracy                           0.99     56960
   macro avg       0.55      0.89      0.59     56960
weighted avg       1.00      0.99      0.99     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 10.0, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'} 
oversampling type : under 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     29700
           1       0.97      0.87      0.92       297

    accuracy                           1.00     29997
   macro avg       0.99      0.93      0.96     29997
weighted avg       1.00      1.00      1.00     29997
              precision    recall  f1-score   support

           0       1.00      0.92      0.96     56870
           1       0.02      0.87      0.03        90

    accuracy                           0.92     56960
   macro avg       0.51      0.89      0.50     56960
weighted avg       1.00      0.92      0.96     56960
              precision    recall  f1-score   support

           0       1.00      0.92      0.96     56863
           1       0.02      0.88      0.04        97

    accuracy                           0.92     56960
   macro avg       0.51      0.90      0.50     56960
weighted avg       1.00      0.92      0.96     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'} 
oversampling type : under 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     29700
           1       0.97      0.81      0.88       297

    accuracy                           1.00     29997
   macro avg       0.98      0.91      0.94     29997
weighted avg       1.00      1.00      1.00     29997
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.31      0.80      0.45        90

    accuracy                           1.00     56960
   macro avg       0.66      0.90      0.72     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.35      0.85      0.49        97

    accuracy                           1.00     56960
   macro avg       0.67      0.92      0.75     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'} 
oversampling type : under 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     29700
           1       0.96      0.84      0.90       297

    accuracy                           1.00     29997
   macro avg       0.98      0.92      0.95     29997
weighted avg       1.00      1.00      1.00     29997
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.26      0.81      0.39        90

    accuracy                           1.00     56960
   macro avg       0.63      0.90      0.70     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.29      0.87      0.43        97

    accuracy                           1.00     56960
   macro avg       0.64      0.93      0.72     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.95      0.84      0.89      1696

    accuracy                           1.00    171830
   macro avg       0.97      0.92      0.95    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.75      0.80      0.77        90

    accuracy                           1.00     56960
   macro avg       0.87      0.90      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.65      0.87      0.74        97

    accuracy                           1.00     56960
   macro avg       0.83      0.93      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.95      0.84      0.89      1696

    accuracy                           1.00    171830
   macro avg       0.97      0.92      0.95    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.75      0.80      0.77        90

    accuracy                           1.00     56960
   macro avg       0.87      0.90      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.65      0.87      0.74        97

    accuracy                           1.00     56960
   macro avg       0.83      0.93      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.01, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'adam', 'verbose': 3} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.99      1.00      0.99      1696

    accuracy                           1.00    171830
   macro avg       0.99      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.76      0.80      0.78        90

    accuracy                           1.00     56960
   macro avg       0.88      0.90      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.72      0.85      0.78        97

    accuracy                           1.00     56960
   macro avg       0.86      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 17, 'solver': 'adam', 'verbose': 3} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      1.00      1.00      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.85      0.79      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.81      0.81      0.81        97

    accuracy                           1.00     56960
   macro avg       0.91      0.91      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 3} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      1.00      1.00      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.77      0.82        90

    accuracy                           1.00     56960
   macro avg       0.94      0.88      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.87      0.78      0.83        97

    accuracy                           1.00     56960
   macro avg       0.94      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 300, 'random_state': 17, 'solver': 'adam', 'verbose': 3} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      1.00      1.00      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.85      0.79      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.81      0.81      0.81        97

    accuracy                           1.00     56960
   macro avg       0.91      0.91      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      1.00      1.00      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.85      0.79      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.81      0.81      0.81        97

    accuracy                           1.00     56960
   macro avg       0.91      0.91      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 64, 32), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.99      1.00      0.99      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.82      0.83        90

    accuracy                           1.00     56960
   macro avg       0.92      0.91      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.99      0.98      0.99      1696

    accuracy                           1.00    171830
   macro avg       0.99      0.99      0.99    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.85      0.82        97

    accuracy                           1.00     56960
   macro avg       0.90      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.99      0.98      0.99      1696

    accuracy                           1.00    171830
   macro avg       0.99      0.99      0.99    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.85      0.82        97

    accuracy                           1.00     56960
   macro avg       0.90      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      0.99      0.99      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.70      0.78        90

    accuracy                           1.00     56960
   macro avg       0.94      0.85      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.87      0.79      0.83        97

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16, 8, 4, 2), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.96      1.00      0.98      1696

    accuracy                           1.00    171830
   macro avg       0.98      1.00      0.99    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.66      0.83      0.74        90

    accuracy                           1.00     56960
   macro avg       0.83      0.92      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.60      0.86      0.70        97

    accuracy                           1.00     56960
   macro avg       0.80      0.93      0.85     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 50, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      0.99      0.99      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.70      0.78        90

    accuracy                           1.00     56960
   macro avg       0.94      0.85      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.87      0.79      0.83        97

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 20, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.99      1.00      0.99      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.82      0.78      0.80        90

    accuracy                           1.00     56960
   macro avg       0.91      0.89      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.76      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.88      0.92      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.01, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 50, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.98      1.00      0.99      1696

    accuracy                           1.00    171830
   macro avg       0.99      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.76      0.78      0.77        90

    accuracy                           1.00     56960
   macro avg       0.88      0.89      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.73      0.85      0.78        97

    accuracy                           1.00     56960
   macro avg       0.86      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16, 8), 'learning_rate_init': 0.01, 'max_iter': 50, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.97      1.00      0.98      1696

    accuracy                           1.00    171830
   macro avg       0.98      1.00      0.99    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.65      0.82      0.73        90

    accuracy                           1.00     56960
   macro avg       0.82      0.91      0.86     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.65      0.87      0.74        97

    accuracy                           1.00     56960
   macro avg       0.82      0.93      0.87     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 50, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      0.99      0.99      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.70      0.78        90

    accuracy                           1.00     56960
   macro avg       0.94      0.85      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.87      0.79      0.83        97

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64, 32), 'learning_rate_init': 0.001, 'max_iter': 50, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      1.00      1.00      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.77      0.82        90

    accuracy                           1.00     56960
   macro avg       0.94      0.88      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.87      0.78      0.83        97

    accuracy                           1.00     56960
   macro avg       0.94      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      1.00      1.00      1696

    accuracy                           1.00    171830
   macro avg       1.00      1.00      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.85      0.79      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.81      0.81      0.81        97

    accuracy                           1.00     56960
   macro avg       0.91      0.91      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.97      0.97      0.97      1696

    accuracy                           1.00    171830
   macro avg       0.99      0.98      0.99    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.73      0.82      0.77        90

    accuracy                           1.00     56960
   macro avg       0.87      0.91      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.70      0.84      0.76        97

    accuracy                           1.00     56960
   macro avg       0.85      0.92      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       1.00      0.99      0.99      1696

    accuracy                           1.00    171830
   macro avg       1.00      0.99      1.00    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.86      0.73      0.79        90

    accuracy                           1.00     56960
   macro avg       0.93      0.87      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.83      0.80      0.82        97

    accuracy                           1.00     56960
   macro avg       0.91      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (16, 8, 2), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.97      0.99      0.98      1696

    accuracy                           1.00    171830
   macro avg       0.99      1.00      0.99    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.72      0.78      0.75        90

    accuracy                           1.00     56960
   macro avg       0.86      0.89      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.70      0.86      0.77        97

    accuracy                           1.00     56960
   macro avg       0.85      0.93      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (8, 4, 2), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.97      0.87      0.92      1696

    accuracy                           1.00    171830
   macro avg       0.98      0.94      0.96    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.73      0.74      0.74        90

    accuracy                           1.00     56960
   macro avg       0.86      0.87      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.72      0.84      0.77        97

    accuracy                           1.00     56960
   macro avg       0.86      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (12, 8, 2), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.99      0.93      0.96      1696

    accuracy                           1.00    171830
   macro avg       1.00      0.97      0.98    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.76      0.81        90

    accuracy                           1.00     56960
   macro avg       0.94      0.88      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.80      0.76      0.78        97

    accuracy                           1.00     56960
   macro avg       0.90      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 0.1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.98      0.98      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.99      0.99    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.82      0.81      0.82        90

    accuracy                           1.00     56960
   macro avg       0.91      0.91      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.76      0.85      0.80        97

    accuracy                           1.00     56960
   macro avg       0.88      0.92      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.78      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.89      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.79      0.83        90

    accuracy                           1.00     56960
   macro avg       0.93      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.84      0.81        97

    accuracy                           1.00     56960
   macro avg       0.90      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.79      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.89      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.85      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.77      0.85      0.80        97

    accuracy                           1.00     56960
   macro avg       0.88      0.92      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 200, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.79      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.89      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.86      0.80      0.83        90

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.76      0.85      0.80        97

    accuracy                           1.00     56960
   macro avg       0.88      0.92      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 500, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.93    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.85      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.85      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.1, 'max_iter': 500, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.93      0.80      0.86      1699

    accuracy                           1.00    171836
   macro avg       0.96      0.90      0.93    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.69      0.80      0.74        90

    accuracy                           1.00     56960
   macro avg       0.84      0.90      0.87     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.67      0.86      0.75        97

    accuracy                           1.00     56960
   macro avg       0.84      0.93      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.78      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.89      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.79      0.83        90

    accuracy                           1.00     56960
   macro avg       0.93      0.89      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.84      0.81        97

    accuracy                           1.00     56960
   macro avg       0.90      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'lbfgs', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      1.00      1.00      1699

    accuracy                           1.00    171836
   macro avg       1.00      1.00      1.00    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.75      0.77      0.76        90

    accuracy                           1.00     56960
   macro avg       0.87      0.88      0.88     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.76      0.81      0.79        97

    accuracy                           1.00     56960
   macro avg       0.88      0.91      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.79      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.78      0.81        90

    accuracy                           1.00     56960
   macro avg       0.92      0.89      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.86      0.80        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'relu', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.94      0.83      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.97      0.92      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.76      0.83      0.79        90

    accuracy                           1.00     56960
   macro avg       0.88      0.92      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.67      0.88      0.76        97

    accuracy                           1.00     56960
   macro avg       0.84      0.94      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 100, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.95      0.83      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.97      0.92      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.79      0.83      0.81        90

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.70      0.88      0.78        97

    accuracy                           1.00     56960
   macro avg       0.85      0.94      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 400, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.94      0.84      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.97      0.92      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.78      0.83      0.81        90

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.67      0.88      0.76        97

    accuracy                           1.00     56960
   macro avg       0.84      0.94      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 400, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.86      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 800, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.86      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 800, 'random_state': 17, 'solver': 'adam', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.94      0.82      0.88      1699

    accuracy                           1.00    171836
   macro avg       0.97      0.91      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.76      0.82      0.79        90

    accuracy                           1.00     56960
   macro avg       0.88      0.91      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.67      0.87      0.76        97

    accuracy                           1.00     56960
   macro avg       0.84      0.93      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (32, 16, 8), 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.86      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.86      0.80        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.86      0.80        97

    accuracy                           1.00     56960
   macro avg       0.88      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 0.001, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.79      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.86      0.80      0.83        90

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 0.01, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.79      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.86      0.80      0.83        90

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.86      0.80        97

    accuracy                           1.00     56960
   macro avg       0.88      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'adaptive', 'learning_rate_init': 0.1, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.80      0.81        90

    accuracy                           1.00     56960
   macro avg       0.91      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.72      0.86      0.78        97

    accuracy                           1.00     56960
   macro avg       0.86      0.93      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.86      0.80        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.95      0.83      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.97      0.92      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.78      0.82      0.80        90

    accuracy                           1.00     56960
   macro avg       0.89      0.91      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.67      0.88      0.76        97

    accuracy                           1.00     56960
   macro avg       0.84      0.94      0.88     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.79      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.89      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.80      0.84        90

    accuracy                           1.00     56960
   macro avg       0.94      0.90      0.92     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.81      0.84      0.82        97

    accuracy                           1.00     56960
   macro avg       0.90      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: standard, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.77      0.86      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.88      0.93    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.77      0.82        90

    accuracy                           1.00     56960
   macro avg       0.94      0.88      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.76      0.79      0.78        97

    accuracy                           1.00     56960
   macro avg       0.88      0.90      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.98      0.79      0.88      1696

    accuracy                           1.00    171830
   macro avg       0.99      0.90      0.94    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.80      0.83        90

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.92     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.85      0.81        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: standard, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.93    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.81      0.77      0.79        90

    accuracy                           1.00     56960
   macro avg       0.91      0.88      0.89     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.96      0.80      0.87      1696

    accuracy                           1.00    171830
   macro avg       0.98      0.90      0.94    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.77      0.80        90

    accuracy                           1.00     56960
   macro avg       0.92      0.88      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.96      0.80      0.87      1696

    accuracy                           1.00    171830
   macro avg       0.98      0.90      0.94    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.83      0.77      0.80        90

    accuracy                           1.00     56960
   macro avg       0.92      0.88      0.90     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.84      0.79        97

    accuracy                           1.00     56960
   macro avg       0.87      0.92      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: logistic regression, scale: robust, feature engineering: 1 ,model params: {'C': 0.1, 'class_weight': None, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.98      0.77      0.86      1696

    accuracy                           1.00    171830
   macro avg       0.99      0.88      0.93    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.77      0.82        90

    accuracy                           1.00     56960
   macro avg       0.94      0.88      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.79      0.77        97

    accuracy                           1.00     56960
   macro avg       0.88      0.90      0.89     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.96      0.80      0.87      1696

    accuracy                           1.00    171830
   macro avg       0.98      0.90      0.94    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.74      0.87      0.80        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: robust, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.98      0.79      0.88      1696

    accuracy                           1.00    171830
   macro avg       0.99      0.90      0.94    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.80      0.83        90

    accuracy                           1.00     56960
   macro avg       0.93      0.90      0.92     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.85      0.81        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.79      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.89      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.80      0.84        90

    accuracy                           1.00     56960
   macro avg       0.94      0.90      0.92     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.81      0.84      0.82        97

    accuracy                           1.00     56960
   macro avg       0.90      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: NN, scale: standard, feature engineering: 1 ,model params: {'activation': 'tanh', 'alpha': 1, 'batch_size': 512, 'hidden_layer_sizes': (64, 32, 16), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'max_iter': 1500, 'random_state': 17, 'solver': 'sgd', 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.96      0.80      0.87      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.75      0.86      0.80        97

    accuracy                           1.00     56960
   macro avg       0.87      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 20, 'min_samples_split': 50, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.82      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.91      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.83      0.86        90

    accuracy                           1.00     56960
   macro avg       0.94      0.92      0.93     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.77      0.85      0.81        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 20, 'min_samples_split': 50, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.82      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.91      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.82      0.85        90

    accuracy                           1.00     56960
   macro avg       0.94      0.91      0.93     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.85      0.81        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 50, 'min_samples_split': 50, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.81      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.91      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.81      0.84        90

    accuracy                           1.00     56960
   macro avg       0.94      0.91      0.92     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.85      0.82        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 50, 'min_samples_split': 25, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.81      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.91      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.81      0.84        90

    accuracy                           1.00     56960
   macro avg       0.94      0.91      0.92     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.85      0.82        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 20, 'min_samples_split': 40, 'n_estimators': 150, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.83      0.89      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.91      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.83      0.86        90

    accuracy                           1.00     56960
   macro avg       0.94      0.92      0.93     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.78      0.85      0.81        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 30, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.98      0.83      0.90      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.88      0.83      0.86        90

    accuracy                           1.00     56960
   macro avg       0.94      0.92      0.93     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.85      0.82        97

    accuracy                           1.00     56960
   macro avg       0.89      0.92      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.84      0.91      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.92      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.87      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.93     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 120, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.88      0.93      1699

    accuracy                           1.00    171836
   macro avg       1.00      0.94      0.97    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.83      0.87        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.85      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.93     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 110, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.86      0.92      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.93      0.96    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.83      0.87        90

    accuracy                           1.00     56960
   macro avg       0.95      0.92      0.93     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.92     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.85      0.92      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.93      0.96    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.90      0.84      0.87        90

    accuracy                           1.00     56960
   macro avg       0.95      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.92     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.84      0.91      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.96    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.82      0.87        90

    accuracy                           1.00     56960
   macro avg       0.96      0.91      0.93     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.85      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.93     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: robust, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170134
           1       0.99      0.84      0.91      1696

    accuracy                           1.00    171830
   macro avg       0.99      0.92      0.95    171830
weighted avg       1.00      1.00      1.00    171830
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.91      0.83      0.87        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.92     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.84      0.91      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.92      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.87      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.93     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.84      0.91      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.92      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.92     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 12, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.85      0.92      1699

    accuracy                           1.00    171836
   macro avg       1.00      0.92      0.96    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.93      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.85      0.85      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.92      0.92     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 12, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.85      0.92      1699

    accuracy                           1.00    171836
   macro avg       1.00      0.93      0.96    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.93      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.85      0.85      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.92      0.92     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 12, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.85      0.91      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.96    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.92      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.85      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.93     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.84      0.91      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.92      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.86      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.92     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Randomforests, scale: standard, feature engineering: 1 ,model params: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 7, 'min_samples_split': 15, 'n_estimators': 100, 'n_jobs': -1, 'random_state': 17, 'verbose': 2} 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.99      0.84      0.91      1699

    accuracy                           1.00    171836
   macro avg       0.99      0.92      0.95    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.92      0.84      0.88        90

    accuracy                           1.00     56960
   macro avg       0.96      0.92      0.94     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.84      0.87      0.85        97

    accuracy                           1.00     56960
   macro avg       0.92      0.93      0.93     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Voting Classifier, scale: standard, feature engineering: 1 ,model params: None 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.81      0.88      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.91      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.87      0.81      0.84        90

    accuracy                           1.00     56960
   macro avg       0.93      0.91      0.92     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.79      0.86      0.82        97

    accuracy                           1.00     56960
   macro avg       0.90      0.93      0.91     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
model: Voting Classifier, scale: standard, feature engineering: 1 ,model params: None 
oversampling type : tsmote 
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    170137
           1       0.97      0.80      0.88      1699

    accuracy                           1.00    171836
   macro avg       0.98      0.90      0.94    171836
weighted avg       1.00      1.00      1.00    171836
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56870
           1       0.84      0.80      0.82        90

    accuracy                           1.00     56960
   macro avg       0.92      0.90      0.91     56960
weighted avg       1.00      1.00      1.00     56960
              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56863
           1       0.77      0.86      0.81        97

    accuracy                           1.00     56960
   macro avg       0.88      0.93      0.90     56960
weighted avg       1.00      1.00      1.00     56960
################################################################
